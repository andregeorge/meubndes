{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BNDES Data Download Receita Federal",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jobv-2peSevK"
      },
      "source": [
        "Projeto Dados Abertos BNDES\n",
        "\n",
        "Download bases da Receita Federal\n",
        "\n",
        "\n",
        ">*Adaptado de Aphonso Henrique do Amaral Rafael*\n",
        ">\n",
        ">*Projeto github: https://github.com/aphonsoar/Receita_Federal_do_Brasil_-_Dados_Publicos_CNPJ*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqBLgQbeuCYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "918dbd9b-5120-4807-e860-bfd22024b9f7"
      },
      "source": [
        "!pip install python-dotenv\n",
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-0.19.0-py2.py3-none-any.whl (17 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-0.19.0\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=9044907e72d39731d464e1c25a7288b7417660e803416a463794900f84d4cf48\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSRPMTlBIjjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03879048-d622-4c66-c7ab-1806038f49bf"
      },
      "source": [
        "from datetime import date\n",
        "from dotenv import load_dotenv\n",
        "from pathlib import Path\n",
        "from sqlalchemy import create_engine\n",
        "import bs4 as bs\n",
        "import ftplib\n",
        "import gzip\n",
        "import os\n",
        "import pandas as pd\n",
        "import psycopg2\n",
        "import re\n",
        "import sys\n",
        "import time\n",
        "import urllib.request\n",
        "import wget\n",
        "import zipfile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_itdGTnDIjx9",
        "outputId": "e358b98b-711d-4a99-a942-49825b8ced0f"
      },
      "source": [
        "#%%\n",
        "def getEnv(env):\n",
        "    return os.getenv(env)\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "# URL source data RFB\n",
        "dados_rf = 'http://200.152.38.155/CNPJ/'\n",
        "output_files = 'output/'\n",
        "extracted_files = 'extracted/'\n",
        "\n",
        "# Create directories to store files\n",
        "if not os.path.exists(output_files):\n",
        "    os.mkdir(output_files)\n",
        "\n",
        "if not os.path.exists(extracted_files):\n",
        "    os.mkdir(extracted_files)\n",
        "\n",
        "raw_html = urllib.request.urlopen(dados_rf)\n",
        "raw_html = raw_html.read()\n",
        "\n",
        "# Get and convert html in string\n",
        "page_items = bs.BeautifulSoup(raw_html, 'lxml')\n",
        "html_str = str(page_items)\n",
        "\n",
        "# Get zip files\n",
        "Files = []\n",
        "text = '.zip'\n",
        "for m in re.finditer(text, html_str):\n",
        "    i_start = m.start()-40\n",
        "    i_end = m.end()\n",
        "    i_loc = html_str[i_start:i_end].find('href=')+6\n",
        "    Files.append(html_str[i_start+i_loc:i_end])\n",
        "\n",
        "print('Arquivos que serão baixados:')\n",
        "i_f = 0\n",
        "for f in Files:\n",
        "    i_f += 1\n",
        "    print(str(i_f) + ' - ' + f)\n",
        "\n",
        "#%%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arquivos que serão baixados:\n",
            "1 - F.K03200$W.SIMPLES.CSV.D10710.zip\n",
            "2 - F.K03200$Z.D10710.CNAECSV.zip\n",
            "3 - F.K03200$Z.D10710.MOTICSV.zip\n",
            "4 - F.K03200$Z.D10710.MUNICCSV.zip\n",
            "5 - F.K03200$Z.D10710.NATJUCSV.zip\n",
            "6 - F.K03200$Z.D10710.PAISCSV.zip\n",
            "7 - F.K03200$Z.D10710.QUALSCSV.zip\n",
            "8 - K3241.K03200Y0.D10710.EMPRECSV.zip\n",
            "9 - K3241.K03200Y0.D10710.ESTABELE.zip\n",
            "10 - K3241.K03200Y0.D10710.SOCIOCSV.zip\n",
            "11 - K3241.K03200Y1.D10710.EMPRECSV.zip\n",
            "12 - K3241.K03200Y1.D10710.ESTABELE.zip\n",
            "13 - K3241.K03200Y1.D10710.SOCIOCSV.zip\n",
            "14 - K3241.K03200Y2.D10710.EMPRECSV.zip\n",
            "15 - K3241.K03200Y2.D10710.ESTABELE.zip\n",
            "16 - K3241.K03200Y2.D10710.SOCIOCSV.zip\n",
            "17 - K3241.K03200Y3.D10710.EMPRECSV.zip\n",
            "18 - K3241.K03200Y3.D10710.ESTABELE.zip\n",
            "19 - K3241.K03200Y3.D10710.SOCIOCSV.zip\n",
            "20 - K3241.K03200Y4.D10710.EMPRECSV.zip\n",
            "21 - K3241.K03200Y4.D10710.ESTABELE.zip\n",
            "22 - K3241.K03200Y4.D10710.SOCIOCSV.zip\n",
            "23 - K3241.K03200Y5.D10710.EMPRECSV.zip\n",
            "24 - K3241.K03200Y5.D10710.ESTABELE.zip\n",
            "25 - K3241.K03200Y5.D10710.SOCIOCSV.zip\n",
            "26 - K3241.K03200Y6.D10710.EMPRECSV.zip\n",
            "27 - K3241.K03200Y6.D10710.ESTABELE.zip\n",
            "28 - K3241.K03200Y6.D10710.SOCIOCSV.zip\n",
            "29 - K3241.K03200Y7.D10710.EMPRECSV.zip\n",
            "30 - K3241.K03200Y7.D10710.ESTABELE.zip\n",
            "31 - K3241.K03200Y7.D10710.SOCIOCSV.zip\n",
            "32 - K3241.K03200Y8.D10710.EMPRECSV.zip\n",
            "33 - K3241.K03200Y8.D10710.ESTABELE.zip\n",
            "34 - K3241.K03200Y8.D10710.SOCIOCSV.zip\n",
            "35 - K3241.K03200Y9.D10710.EMPRECSV.zip\n",
            "36 - K3241.K03200Y9.D10710.ESTABELE.zip\n",
            "37 - K3241.K03200Y9.D10710.SOCIOCSV.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIGaJG9xIj1I"
      },
      "source": [
        "########################################################################################################################\n",
        "## DOWNLOAD ############################################################################################################\n",
        "########################################################################################################################\n",
        "\n",
        "# Download files\n",
        "# Create this bar_progress method which is invoked automatically from wget:\n",
        "def bar_progress(current, total, width=80):\n",
        "  progress_message = \"Downloading: %d%% [%d / %d] bytes - \" % (current / total * 100, current, total)\n",
        "  # Don't use print() as it will print in new line every time.\n",
        "  sys.stdout.write(\"\\r\" + progress_message)\n",
        "  sys.stdout.flush()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLQ8SMC1pS5L"
      },
      "source": [
        "# Download files\n",
        "def download_files(files_list,output_files):\n",
        "  i_l = 0\n",
        "  for l in files_list:\n",
        "    i_l += 1\n",
        "    print('Baixando arquivo:')\n",
        "    print(str(i_l) + ' - ' + l)\n",
        "    url = dados_rf+l\n",
        "    wget.download(url, out=output_files, bar=bar_progress)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eewa9wNyNzmw"
      },
      "source": [
        "# Extract files\n",
        "def extract_files(files_list,output_files,extracted_files):  \n",
        "  i_l = 0\n",
        "  for l in files_list:\n",
        "    try:\n",
        "      i_l += 1\n",
        "      print('Descompactando arquivo:')\n",
        "      print(str(i_l) + ' - ' + l)\n",
        "      with zipfile.ZipFile(output_files + l, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extracted_files)\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma6gTKyHOHtk"
      },
      "source": [
        "# Download layout:\n",
        "url_layout = 'https://www.gov.br/receitafederal/pt-br/assuntos/orientacao-tributaria/cadastros/consultas/arquivos/NOVOLAYOUTDOSDADOSABERTOSDOCNPJ.pdf'\n",
        "print('Baixando layout:')\n",
        "wget.download(url_layout, out=output_files, bar=bar_progress)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-ANCUn2S9pp"
      },
      "source": [
        "# Generate list by topic\n",
        "arquivos_empresa = []\n",
        "arquivos_estabelecimento = []\n",
        "arquivos_socios = []\n",
        "arquivos_simples = []\n",
        "arquivos_cnae = []\n",
        "arquivos_moti = []\n",
        "arquivos_munic = []\n",
        "arquivos_natju = []\n",
        "arquivos_pais = []\n",
        "arquivos_quals = []\n",
        "for i in range(len(Files)):\n",
        "    if Files[i].find('EMPRE') > -1:\n",
        "        arquivos_empresa.append(Files[i])\n",
        "    elif Files[i].find('ESTABELE') > -1:\n",
        "        arquivos_estabelecimento.append(Files[i])\n",
        "    elif Files[i].find('SOCIO') > -1:\n",
        "        arquivos_socios.append(Files[i])\n",
        "    elif Files[i].find('SIMPLES') > -1:\n",
        "        arquivos_simples.append(Files[i])\n",
        "    elif Files[i].find('CNAE') > -1:\n",
        "        arquivos_cnae.append(Files[i])\n",
        "    elif Files[i].find('MOTI') > -1:\n",
        "        arquivos_moti.append(Files[i])\n",
        "    elif Files[i].find('MUNIC') > -1:\n",
        "        arquivos_munic.append(Files[i])\n",
        "    elif Files[i].find('NATJU') > -1:\n",
        "        arquivos_natju.append(Files[i])\n",
        "    elif Files[i].find('PAIS') > -1:\n",
        "        arquivos_pais.append(Files[i])\n",
        "    elif Files[i].find('QUALS') > -1:\n",
        "        arquivos_quals.append(Files[i])\n",
        "    else:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeGFWu26NmCb"
      },
      "source": [
        "# Download and extract EMPRESA\n",
        "download_files(arquivos_empresa,output_files)\n",
        "extract_files(arquivos_empresa,output_files,extracted_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSyE2iibzymH"
      },
      "source": [
        "# Download ESTABELECIMENTO\n",
        "download_files(arquivos_estabelecimento,output_files)\n",
        "extract_files(arquivos_estabelecimento,output_files,extracted_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RqQVJNRzy5I"
      },
      "source": [
        "# Download SOCIOS\n",
        "download_files(arquivos_socio,output_files)\n",
        "extract_files(arquivos_socio,output_files,extracted_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF0xgq9qzzB7"
      },
      "source": [
        "# Download SIMPLES\n",
        "download_files(arquivos_simples,output_files)\n",
        "extract_files(arquivos_simples,output_files,extracted_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZTg78z4zzGo"
      },
      "source": [
        "# Download CNAE\n",
        "download_files(arquivos_cnae,output_files)\n",
        "extract_files(arquivos_cnae,output_files,extracted_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwx1vtzqzzMO"
      },
      "source": [
        "# Download MOTIVO\n",
        "download_files(arquivos_moti,output_files)\n",
        "extract_files(arquivos_moti,output_files,extracted_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6AqYBODzzSJ"
      },
      "source": [
        "# Download MUNICIPIO\n",
        "download_files(arquivos_munic,output_files)\n",
        "extract_files(arquivos_munic,output_files,extracted_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjqLBh9a0JGd"
      },
      "source": [
        "# Download QUALIFICACOES\n",
        "download_files(arquivos_natju,output_files)\n",
        "extract_files(arquivos_natju,output_files,extract_files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0jpg_lZS038",
        "outputId": "833b93f3-ae44-49a9-a0ec-aff32e002711"
      },
      "source": [
        "# Arquivos de empresa:\n",
        "empresa_insert_start = time.time()\n",
        "print(\"\"\"\n",
        "#######################\n",
        "## Arquivos de EMPRESA:\n",
        "#######################\n",
        "\"\"\")\n",
        "\n",
        "for e in range(0, len(arquivos_empresa)):\n",
        "    print('Trabalhando no arquivo: '+arquivos_empresa[e]+' [...]')\n",
        "    try:\n",
        "        del empresa\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    empresa = pd.DataFrame(columns=[0, 1, 2, 3, 4, 5, 6])\n",
        "    empresa_dtypes = {0: 'object', 1: 'object', 2: 'object', 3: 'object', 4: 'object', 5: 'object', 6: 'object'}\n",
        "    extracted_file_path = Path(f'{extracted_files}/{arquivos_empresa[e]}')\n",
        "\n",
        "    empresa = pd.read_csv(extracted_file_path,\n",
        "                          sep=';',\n",
        "                          decimal=',', \n",
        "                          encoding='ISO-8859-1', #'UTF-8',\n",
        "                          #nrows=100,\n",
        "                          skiprows=0,\n",
        "                          header=None,\n",
        "                          dtype=empresa_dtypes)\n",
        "\n",
        "    # Tratamento do arquivo antes de inserir na base:\n",
        "    empresa = empresa.reset_index()\n",
        "    del empresa['index']\n",
        "\n",
        "    # Renomear colunas\n",
        "    empresa.columns = ['cnpj_basico', 'razao_social', 'natureza_juridica', 'qualificacao_responsavel', 'capital_social', 'porte_empresa', 'ente_federativo_responsavel']\n",
        "\n",
        "    # Replace \",\" por \".\"\n",
        "    empresa['capital_social'] = empresa['capital_social'].apply(lambda x: x.replace(',','.'))\n",
        "    empresa['capital_social'] = empresa['capital_social'].astype(float)\n",
        "\n",
        "    # Gravar dados no banco:\n",
        "    # Empresa\n",
        "    empresa.to_parquet(arquivos_empresa[e]+'.parquet',engine='pyarrow',compression='gzip')\n",
        "    print('Arquivo ' + arquivos_empresa[e] + ' inserido com sucesso no banco de dados!')\n",
        "\n",
        "try:\n",
        "    del empresa\n",
        "except:\n",
        "    pass\n",
        "print('Arquivos de empresa finalizados!')\n",
        "empresa_insert_end = time.time()\n",
        "empresa_Tempo_insert = round((empresa_insert_end - empresa_insert_start))\n",
        "print('Tempo de execução do processo de empresa (em segundos): ' + str(empresa_Tempo_insert))\n",
        "\n",
        "#%%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "#######################\n",
            "## Arquivos de EMPRESA:\n",
            "#######################\n",
            "\n",
            "Trabalhando no arquivo: K3241.K03200Y9.D10710.EMPRECSV [...]\n",
            "Arquivo K3241.K03200Y9.D10710.EMPRECSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y6.D10710.EMPRECSV [...]\n",
            "Arquivo K3241.K03200Y6.D10710.EMPRECSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y2.D10710.EMPRECSV [...]\n",
            "Arquivo K3241.K03200Y2.D10710.EMPRECSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y0.D10710.EMPRECSV [...]\n",
            "Arquivo K3241.K03200Y0.D10710.EMPRECSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y1.D10710.EMPRECSV [...]\n",
            "Arquivo K3241.K03200Y1.D10710.EMPRECSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y4.D10710.EMPRECSV [...]\n",
            "Arquivo K3241.K03200Y4.D10710.EMPRECSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y8.D10710.EMPRECSV [...]\n",
            "Arquivo K3241.K03200Y8.D10710.EMPRECSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y3.D10710.EMPRECSV [...]\n",
            "Arquivo K3241.K03200Y3.D10710.EMPRECSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y5.D10710.EMPRECSV [...]\n",
            "Arquivo K3241.K03200Y5.D10710.EMPRECSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y7.D10710.EMPRECSV [...]\n",
            "Arquivo K3241.K03200Y7.D10710.EMPRECSV inserido com sucesso no banco de dados!\n",
            "Arquivos de empresa finalizados!\n",
            "Tempo de execução do processo de empresa (em segundos): 299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBxSTbFUePgT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b635ccc5-1bcf-42c2-87f0-31bb508dd39b"
      },
      "source": [
        "#%%\n",
        "# Arquivos de estabelecimento:\n",
        "estabelecimento_insert_start = time.time()\n",
        "print(\"\"\"\n",
        "############################### \n",
        "## Arquivos de ESTABELECIMENTO:\n",
        "###############################\n",
        "\"\"\")\n",
        "\n",
        "# Drop table antes do insert\n",
        "#cur.execute('DROP TABLE IF EXISTS \"estabelecimento\";')\n",
        "#conn.commit()\n",
        "\n",
        "for e in range(0, len(arquivos_estabelecimento)):\n",
        "    print('Trabalhando no arquivo: '+arquivos_estabelecimento[e]+' [...]')\n",
        "    try:\n",
        "        del estabelecimento\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    estabelecimento = pd.DataFrame(columns=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28])\n",
        "    extracted_file_path = Path(f'{extracted_files}/{arquivos_estabelecimento[e]}')\n",
        "\n",
        "    estabelecimento = pd.read_csv(filepath_or_buffer=extracted_file_path,\n",
        "                          sep=';',\n",
        "                          encoding='ISO-8859-1', #'UTF-8',\n",
        "                          #nrows=100,\n",
        "                          skiprows=0,\n",
        "                          header=None,\n",
        "                          dtype='object')\n",
        "\n",
        "    # Tratamento do arquivo antes de inserir na base:\n",
        "    estabelecimento = estabelecimento.reset_index()\n",
        "    del estabelecimento['index']\n",
        "\n",
        "    # Renomear colunas\n",
        "    estabelecimento.columns = ['cnpj_basico',\n",
        "                               'cnpj_ordem',\n",
        "                               'cnpj_dv',\n",
        "                               'identificador_matriz_filial',\n",
        "                               'nome_fantasia',\n",
        "                               'situacao_cadastral',\n",
        "                               'data_situacao_cadastral',\n",
        "                               'motivo_situacao_cadastral',\n",
        "                               'nome_cidade_exterior',\n",
        "                               'pais',\n",
        "                               'data_inicio_atividade',\n",
        "                               'cnae_fiscal_principal',\n",
        "                               'cnae_fiscal_secundaria',\n",
        "                               'tipo_logradouro',\n",
        "                               'logradouro',\n",
        "                               'numero',\n",
        "                               'complemento',\n",
        "                               'bairro',\n",
        "                               'cep',\n",
        "                               'uf',\n",
        "                               'municipio',\n",
        "                               'ddd_1',\n",
        "                               'telefone_1',\n",
        "                               'ddd_2',\n",
        "                               'telefone_2',\n",
        "                               'ddd_fax',\n",
        "                               'fax',\n",
        "                               'correio_eletronico',\n",
        "                               'situacao_especial',\n",
        "                               'data_situacao_especial']\n",
        "\n",
        "    # Gravar dados no banco:\n",
        "    # estabelecimento\n",
        "    estabelecimento.to_parquet(arquivos_estabelecimento[e]+'.parquet',engine='pyarrow',compression='gzip')\n",
        "    print('Arquivo ' + arquivos_estabelecimento[e] + ' inserido com sucesso no banco de dados!')\n",
        "\n",
        "try:\n",
        "    del estabelecimento\n",
        "except:\n",
        "    pass\n",
        "print('Arquivos de estabelecimento finalizados!')\n",
        "estabelecimento_insert_end = time.time()\n",
        "estabelecimento_Tempo_insert = round((estabelecimento_insert_end - estabelecimento_insert_start))\n",
        "print('Tempo de execução do processo de estabelecimento (em segundos): ' + str(estabelecimento_Tempo_insert))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "############################### \n",
            "## Arquivos de ESTABELECIMENTO:\n",
            "###############################\n",
            "\n",
            "Trabalhando no arquivo: K3241.K03200Y5.D10710.ESTABELE [...]\n",
            "Arquivo K3241.K03200Y5.D10710.ESTABELE inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y2.D10710.ESTABELE [...]\n",
            "Arquivo K3241.K03200Y2.D10710.ESTABELE inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y0.D10710.ESTABELE [...]\n",
            "Arquivo K3241.K03200Y0.D10710.ESTABELE inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y3.D10710.ESTABELE [...]\n",
            "Arquivo K3241.K03200Y3.D10710.ESTABELE inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y8.D10710.ESTABELE [...]\n",
            "Arquivo K3241.K03200Y8.D10710.ESTABELE inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y9.D10710.ESTABELE [...]\n",
            "Arquivo K3241.K03200Y9.D10710.ESTABELE inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y4.D10710.ESTABELE [...]\n",
            "Arquivo K3241.K03200Y4.D10710.ESTABELE inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y1.D10710.ESTABELE [...]\n",
            "Arquivo K3241.K03200Y1.D10710.ESTABELE inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y7.D10710.ESTABELE [...]\n",
            "Arquivo K3241.K03200Y7.D10710.ESTABELE inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y6.D10710.ESTABELE [...]\n",
            "Arquivo K3241.K03200Y6.D10710.ESTABELE inserido com sucesso no banco de dados!\n",
            "Arquivos de estabelecimento finalizados!\n",
            "Tempo de execução do processo de estabelecimento (em segundos): 1095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j5xliZ9wfKOQ",
        "outputId": "2c98c0c8-88c1-475f-b851-011af48be5b3"
      },
      "source": [
        "#%%\n",
        "# Arquivos de socios:\n",
        "socios_insert_start = time.time()\n",
        "print(\"\"\"\n",
        "######################\n",
        "## Arquivos de SOCIOS:\n",
        "######################\n",
        "\"\"\")\n",
        "\n",
        "for e in range(0, len(arquivos_socios)):\n",
        "    print('Trabalhando no arquivo: '+arquivos_socios[e]+' [...]')\n",
        "    try:\n",
        "        del socios\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    extracted_file_path = Path(f'{extracted_files}/{arquivos_socios[e]}')\n",
        "    socios = pd.DataFrame(columns=[1,2,3,4,5,6,7,8,9,10,11])\n",
        "    socios = pd.read_csv(filepath_or_buffer=extracted_file_path,\n",
        "                          sep=';',\n",
        "                          encoding='ISO-8859-1', #'UTF-8',\n",
        "                          #nrows=100,\n",
        "                          skiprows=0,\n",
        "                          header=None,\n",
        "                          dtype='object')\n",
        "\n",
        "    # Tratamento do arquivo antes de inserir na base:\n",
        "    socios = socios.reset_index()\n",
        "    del socios['index']\n",
        "\n",
        "    # Renomear colunas\n",
        "    socios.columns = ['cnpj_basico',\n",
        "                      'identificador_socio',\n",
        "                      'nome_socio_razao_social',\n",
        "                      'cpf_cnpj_socio',\n",
        "                      'qualificacao_socio',\n",
        "                      'data_entrada_sociedade',\n",
        "                      'pais',\n",
        "                      'representante_legal',\n",
        "                      'nome_do_representante',\n",
        "                      'qualificacao_representante_legal',\n",
        "                      'faixa_etaria']\n",
        "\n",
        "    # Gravar dados no banco:\n",
        "    # socios\n",
        "    socios.to_parquet(arquivos_socios[e]+'.parquet',engine='pyarrow',compression='gzip')\n",
        "    print('Arquivo ' + arquivos_socios[e] + ' inserido com sucesso no banco de dados!')\n",
        "\n",
        "try:\n",
        "    del socios\n",
        "except:\n",
        "    pass\n",
        "print('Arquivos de socios finalizados!')\n",
        "socios_insert_end = time.time()\n",
        "socios_Tempo_insert = round((socios_insert_end - socios_insert_start))\n",
        "print('Tempo de execução do processo de sócios (em segundos): ' + str(socios_Tempo_insert))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "######################\n",
            "## Arquivos de SOCIOS:\n",
            "######################\n",
            "\n",
            "Trabalhando no arquivo: K3241.K03200Y9.D10710.SOCIOCSV [...]\n",
            "Arquivo K3241.K03200Y9.D10710.SOCIOCSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y4.D10710.SOCIOCSV [...]\n",
            "Arquivo K3241.K03200Y4.D10710.SOCIOCSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y1.D10710.SOCIOCSV [...]\n",
            "Arquivo K3241.K03200Y1.D10710.SOCIOCSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y2.D10710.SOCIOCSV [...]\n",
            "Arquivo K3241.K03200Y2.D10710.SOCIOCSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y8.D10710.SOCIOCSV [...]\n",
            "Arquivo K3241.K03200Y8.D10710.SOCIOCSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y3.D10710.SOCIOCSV [...]\n",
            "Arquivo K3241.K03200Y3.D10710.SOCIOCSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y0.D10710.SOCIOCSV [...]\n",
            "Arquivo K3241.K03200Y0.D10710.SOCIOCSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y5.D10710.SOCIOCSV [...]\n",
            "Arquivo K3241.K03200Y5.D10710.SOCIOCSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y6.D10710.SOCIOCSV [...]\n",
            "Arquivo K3241.K03200Y6.D10710.SOCIOCSV inserido com sucesso no banco de dados!\n",
            "Trabalhando no arquivo: K3241.K03200Y7.D10710.SOCIOCSV [...]\n",
            "Arquivo K3241.K03200Y7.D10710.SOCIOCSV inserido com sucesso no banco de dados!\n",
            "Arquivos de socios finalizados!\n",
            "Tempo de execução do processo de sócios (em segundos): 192\n",
            "\n",
            "################################\n",
            "## Arquivos do SIMPLES NACIONAL:\n",
            "################################\n",
            "\n",
            "Trabalhando no arquivo: F.K03200$W.SIMPLES.CSV.D10710 [...]\n",
            "Lendo o arquivo F.K03200$W.SIMPLES.CSV.D10710 [...]\n",
            "Linhas no arquivo do Simples F.K03200$W.SIMPLES.CSV.D10710: 28546143\n",
            "Este arquivo será dividido em 29 partes para inserção no banco de dados\n",
            "Iniciando a parte 1 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 1\n",
            "Iniciando a parte 2 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 2\n",
            "Iniciando a parte 3 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 3\n",
            "Iniciando a parte 4 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 4\n",
            "Iniciando a parte 5 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 5\n",
            "Iniciando a parte 6 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 6\n",
            "Iniciando a parte 7 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 7\n",
            "Iniciando a parte 8 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 8\n",
            "Iniciando a parte 9 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 9\n",
            "Iniciando a parte 10 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 10\n",
            "Iniciando a parte 11 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 11\n",
            "Iniciando a parte 12 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 12\n",
            "Iniciando a parte 13 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 13\n",
            "Iniciando a parte 14 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 14\n",
            "Iniciando a parte 15 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 15\n",
            "Iniciando a parte 16 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 16\n",
            "Iniciando a parte 17 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 17\n",
            "Iniciando a parte 18 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 18\n",
            "Iniciando a parte 19 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 19\n",
            "Iniciando a parte 20 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 20\n",
            "Iniciando a parte 21 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 21\n",
            "Iniciando a parte 22 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 22\n",
            "Iniciando a parte 23 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 23\n",
            "Iniciando a parte 24 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 24\n",
            "Iniciando a parte 25 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 25\n",
            "Iniciando a parte 26 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 26\n",
            "Iniciando a parte 27 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 27\n",
            "Iniciando a parte 28 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 28\n",
            "Iniciando a parte 29 [...]\n",
            "Arquivo F.K03200$W.SIMPLES.CSV.D10710 inserido com sucesso no banco de dados! - Parte 29\n",
            "Arquivos do simples finalizados!\n",
            "Tempo de execução do processo do Simples Nacional (em segundos): 199\n",
            "\n",
            "######################\n",
            "## Arquivos de cnae:\n",
            "######################\n",
            "\n",
            "Trabalhando no arquivo: F.K03200$Z.D10710.CNAECSV [...]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-399c7dc58f7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mextracted_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{extracted_files}/{arquivos_cnae[e]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mcnae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mcnae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextracted_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiprows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ANSI'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;31m# Tratamento do arquivo antes de inserir na base:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;31m# We will handle the newline character ourselves later on.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1998\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1999\u001b[0;31m                 \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextIOWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: unknown encoding: ansi"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjTiROr5SCdu"
      },
      "source": [
        "#%%\n",
        "# Arquivos de simples:\n",
        "simples_insert_start = time.time()\n",
        "print(\"\"\"\n",
        "################################\n",
        "## Arquivos do SIMPLES NACIONAL:\n",
        "################################\n",
        "\"\"\")\n",
        "\n",
        "for e in range(0, len(arquivos_simples)):\n",
        "    print('Trabalhando no arquivo: '+arquivos_simples[e]+' [...]')\n",
        "    try:\n",
        "        del simples\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Verificar tamanho do arquivo:\n",
        "    print('Lendo o arquivo ' + arquivos_simples[e]+' [...]')\n",
        "    extracted_file_path = Path(f'{extracted_files}/{arquivos_simples[e]}')\n",
        "\n",
        "    simples_lenght = sum(1 for line in open(extracted_file_path, \"r\"))\n",
        "    print('Linhas no arquivo do Simples '+ arquivos_simples[e] +': '+str(simples_lenght))\n",
        "\n",
        "    tamanho_das_partes = 1000000 # Registros por carga\n",
        "    partes = round(simples_lenght / tamanho_das_partes)\n",
        "    nrows = tamanho_das_partes\n",
        "    skiprows = 0\n",
        "\n",
        "    print('Este arquivo será dividido em ' + str(partes) + ' partes para inserção no banco de dados')\n",
        "\n",
        "    for i in range(0, partes):\n",
        "        print('Iniciando a parte ' + str(i+1) + ' [...]')\n",
        "        simples = pd.DataFrame(columns=[1,2,3,4,5,6])\n",
        "\n",
        "        simples = pd.read_csv(filepath_or_buffer=extracted_file_path,\n",
        "                              sep=';',\n",
        "                              encoding='ISO-8859-1', #'UTF-8',\n",
        "                              nrows=nrows,\n",
        "                              skiprows=skiprows,\n",
        "                              header=None,\n",
        "                              dtype='object')\n",
        "\n",
        "        # Tratamento do arquivo antes de inserir na base:\n",
        "        simples = simples.reset_index()\n",
        "        del simples['index']\n",
        "\n",
        "        # Renomear colunas\n",
        "        simples.columns = ['cnpj_basico',\n",
        "                           'opcao_pelo_simples',\n",
        "                           'data_opcao_simples',\n",
        "                           'data_exclusao_simples',\n",
        "                           'opcao_mei',\n",
        "                           'data_opcao_mei',\n",
        "                           'data_exclusao_mei']\n",
        "\n",
        "        skiprows = skiprows+nrows\n",
        "\n",
        "        # Gravar dados no banco:\n",
        "        # simples\n",
        "        simples.to_parquet(arquivos_simples[e]+'.parquet',engine='pyarrow',compression='gzip')\n",
        "        print('Arquivo ' + arquivos_simples[e] + ' inserido com sucesso no banco de dados! - Parte '+ str(i+1))\n",
        "\n",
        "        try:\n",
        "            del simples\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "try:\n",
        "    del simples\n",
        "except:\n",
        "    pass\n",
        "\n",
        "print('Arquivos do simples finalizados!')\n",
        "simples_insert_end = time.time()\n",
        "simples_Tempo_insert = round((simples_insert_end - simples_insert_start))\n",
        "print('Tempo de execução do processo do Simples Nacional (em segundos): ' + str(simples_Tempo_insert))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zS5Av9TQoumx",
        "outputId": "78d27042-4f79-44cc-a52b-5db54d400dab"
      },
      "source": [
        "#%%\n",
        "# Arquivos de cnae:\n",
        "cnae_insert_start = time.time()\n",
        "print(\"\"\"\n",
        "######################\n",
        "## Arquivos de cnae:\n",
        "######################\n",
        "\"\"\")\n",
        "\n",
        "for e in range(0, len(arquivos_cnae)):\n",
        "    print('Trabalhando no arquivo: '+arquivos_cnae[e]+' [...]')\n",
        "    try:\n",
        "        del cnae\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    extracted_file_path = Path(f'{extracted_files}/{arquivos_cnae[e]}')\n",
        "    cnae = pd.DataFrame(columns=[1,2])\n",
        "    cnae = pd.read_csv(filepath_or_buffer=extracted_file_path, sep=';', encoding='ISO-8859-1', skiprows=0, header=None, dtype='object')\n",
        "\n",
        "    # Tratamento do arquivo antes de inserir na base:\n",
        "    cnae = cnae.reset_index()\n",
        "    del cnae['index']\n",
        "\n",
        "    # Renomear colunas\n",
        "    cnae.columns = ['codigo', 'descricao']\n",
        "\n",
        "    # Gravar dados no banco:\n",
        "    # cnae\n",
        "    cnae.to_parquet(arquivos_cnae[e]+'.parquet',engine='pyarrow',compression='gzip')\n",
        "    print('Arquivo ' + arquivos_cnae[e] + ' inserido com sucesso no banco de dados!')\n",
        "\n",
        "try:\n",
        "    del cnae\n",
        "except:\n",
        "    pass\n",
        "print('Arquivos de cnae finalizados!')\n",
        "cnae_insert_end = time.time()\n",
        "cnae_Tempo_insert = round((cnae_insert_end - cnae_insert_start))\n",
        "print('Tempo de execução do processo de cnae (em segundos): ' + str(cnae_Tempo_insert))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "######################\n",
            "## Arquivos de cnae:\n",
            "######################\n",
            "\n",
            "Trabalhando no arquivo: F.K03200$Z.D10710.CNAECSV [...]\n",
            "Arquivo F.K03200$Z.D10710.CNAECSV inserido com sucesso no banco de dados!\n",
            "Arquivos de cnae finalizados!\n",
            "Tempo de execução do processo de cnae (em segundos): 0\n",
            "\n",
            "#########################################\n",
            "## Arquivos de motivos da situação atual:\n",
            "#########################################\n",
            "\n",
            "Trabalhando no arquivo: F.K03200$Z.D10710.MOTICSV [...]\n",
            "Arquivo F.K03200$Z.D10710.MOTICSV inserido com sucesso no banco de dados!\n",
            "Arquivos de moti finalizados!\n",
            "Tempo de execução do processo de motivos da situação atual (em segundos): 0\n",
            "\n",
            "##########################\n",
            "## Arquivos de municípios:\n",
            "##########################\n",
            "\n",
            "Trabalhando no arquivo: F.K03200$Z.D10710.MUNICCSV [...]\n",
            "Arquivo F.K03200$Z.D10710.MUNICCSV inserido com sucesso no banco de dados!\n",
            "Arquivos de munic finalizados!\n",
            "Tempo de execução do processo de municípios (em segundos): 0\n",
            "\n",
            "#################################\n",
            "## Arquivos de natureza jurídica:\n",
            "#################################\n",
            "\n",
            "Trabalhando no arquivo: F.K03200$Z.D10710.NATJUCSV [...]\n",
            "Arquivo F.K03200$Z.D10710.NATJUCSV inserido com sucesso no banco de dados!\n",
            "Arquivos de natju finalizados!\n",
            "Tempo de execução do processo de natureza jurídica (em segundos): 0\n",
            "\n",
            "######################\n",
            "## Arquivos de país:\n",
            "######################\n",
            "\n",
            "Trabalhando no arquivo: F.K03200$Z.D10710.PAISCSV [...]\n",
            "Arquivo F.K03200$Z.D10710.PAISCSV inserido com sucesso no banco de dados!\n",
            "Arquivos de pais finalizados!\n",
            "Tempo de execução do processo de país (em segundos): 0\n",
            "\n",
            "######################################\n",
            "## Arquivos de qualificação de sócios:\n",
            "######################################\n",
            "\n",
            "Trabalhando no arquivo: F.K03200$Z.D10710.QUALSCSV [...]\n",
            "Arquivo F.K03200$Z.D10710.QUALSCSV inserido com sucesso no banco de dados!\n",
            "Arquivos de quals finalizados!\n",
            "Tempo de execução do processo de qualificação de sócios (em segundos): 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-d2933c0edb6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;31m#%%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0minsert_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m \u001b[0mTempo_insert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minsert_end\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0minsert_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m print(\"\"\"\n",
            "\u001b[0;31mNameError\u001b[0m: name 'insert_start' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1kBisj5SI5t"
      },
      "source": [
        "#%%\n",
        "# Arquivos de moti:\n",
        "moti_insert_start = time.time()\n",
        "print(\"\"\"\n",
        "#########################################\n",
        "## Arquivos de motivos da situação atual:\n",
        "#########################################\n",
        "\"\"\")\n",
        "\n",
        "for e in range(0, len(arquivos_moti)):\n",
        "    print('Trabalhando no arquivo: '+arquivos_moti[e]+' [...]')\n",
        "    try:\n",
        "        del moti\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    extracted_file_path = Path(f'{extracted_files}/{arquivos_moti[e]}')\n",
        "    moti = pd.DataFrame(columns=[1,2])\n",
        "    moti = pd.read_csv(filepath_or_buffer=extracted_file_path, sep=';', encoding='ISO-8859-1', skiprows=0, header=None, dtype='object')\n",
        "\n",
        "    # Tratamento do arquivo antes de inserir na base:\n",
        "    moti = moti.reset_index()\n",
        "    del moti['index']\n",
        "\n",
        "    # Renomear colunas\n",
        "    moti.columns = ['codigo', 'descricao']\n",
        "\n",
        "    # Gravar dados no banco:\n",
        "    # moti\n",
        "    moti.to_parquet(arquivos_moti[e]+'.parquet',engine='pyarrow',compression='gzip')\n",
        "    print('Arquivo ' + arquivos_moti[e] + ' inserido com sucesso no banco de dados!')\n",
        "\n",
        "try:\n",
        "    del moti\n",
        "except:\n",
        "    pass\n",
        "print('Arquivos de moti finalizados!')\n",
        "moti_insert_end = time.time()\n",
        "moti_Tempo_insert = round((moti_insert_end - moti_insert_start))\n",
        "print('Tempo de execução do processo de motivos da situação atual (em segundos): ' + str(moti_Tempo_insert))\n",
        "\n",
        "#%%\n",
        "# Arquivos de munic:\n",
        "munic_insert_start = time.time()\n",
        "print(\"\"\"\n",
        "##########################\n",
        "## Arquivos de municípios:\n",
        "##########################\n",
        "\"\"\")\n",
        "\n",
        "for e in range(0, len(arquivos_munic)):\n",
        "    print('Trabalhando no arquivo: '+arquivos_munic[e]+' [...]')\n",
        "    try:\n",
        "        del munic\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    extracted_file_path = Path(f'{extracted_files}/{arquivos_munic[e]}')\n",
        "    munic = pd.DataFrame(columns=[1,2])\n",
        "    munic = pd.read_csv(filepath_or_buffer=extracted_file_path, sep=';', encoding='ISO-8859-1', skiprows=0, header=None, dtype='object')\n",
        "\n",
        "    # Tratamento do arquivo antes de inserir na base:\n",
        "    munic = munic.reset_index()\n",
        "    del munic['index']\n",
        "\n",
        "    # Renomear colunas\n",
        "    munic.columns = ['codigo', 'descricao']\n",
        "\n",
        "    # Gravar dados no banco:\n",
        "    # munic\n",
        "    munic.to_parquet(arquivos_munic[e]+'.parquet',engine='pyarrow',compression='gzip')\n",
        "    print('Arquivo ' + arquivos_munic[e] + ' inserido com sucesso no banco de dados!')\n",
        "\n",
        "try:\n",
        "    del munic\n",
        "except:\n",
        "    pass\n",
        "print('Arquivos de munic finalizados!')\n",
        "munic_insert_end = time.time()\n",
        "munic_Tempo_insert = round((munic_insert_end - munic_insert_start))\n",
        "print('Tempo de execução do processo de municípios (em segundos): ' + str(munic_Tempo_insert))\n",
        "\n",
        "#%%\n",
        "# Arquivos de natju:\n",
        "natju_insert_start = time.time()\n",
        "print(\"\"\"\n",
        "#################################\n",
        "## Arquivos de natureza jurídica:\n",
        "#################################\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "for e in range(0, len(arquivos_natju)):\n",
        "    print('Trabalhando no arquivo: '+arquivos_natju[e]+' [...]')\n",
        "    try:\n",
        "        del natju\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    extracted_file_path = Path(f'{extracted_files}/{arquivos_natju[e]}')\n",
        "    natju = pd.DataFrame(columns=[1,2])\n",
        "    natju = pd.read_csv(filepath_or_buffer=extracted_file_path, sep=';', encoding='ISO-8859-1', skiprows=0, header=None, dtype='object')\n",
        "\n",
        "    # Tratamento do arquivo antes de inserir na base:\n",
        "    natju = natju.reset_index()\n",
        "    del natju['index']\n",
        "\n",
        "    # Renomear colunas\n",
        "    natju.columns = ['codigo', 'descricao']\n",
        "\n",
        "    # Gravar dados no banco:\n",
        "    # natju\n",
        "    natju.to_parquet(arquivos_natju[e]+'.parquet',engine='pyarrow',compression='gzip')\n",
        "    print('Arquivo ' + arquivos_natju[e] + ' inserido com sucesso no banco de dados!')\n",
        "\n",
        "try:\n",
        "    del natju\n",
        "except:\n",
        "    pass\n",
        "print('Arquivos de natju finalizados!')\n",
        "natju_insert_end = time.time()\n",
        "natju_Tempo_insert = round((natju_insert_end - natju_insert_start))\n",
        "print('Tempo de execução do processo de natureza jurídica (em segundos): ' + str(natju_Tempo_insert))\n",
        "\n",
        "#%%\n",
        "# Arquivos de pais:\n",
        "pais_insert_start = time.time()\n",
        "print(\"\"\"\n",
        "######################\n",
        "## Arquivos de país:\n",
        "######################\n",
        "\"\"\")\n",
        "\n",
        "for e in range(0, len(arquivos_pais)):\n",
        "    print('Trabalhando no arquivo: '+arquivos_pais[e]+' [...]')\n",
        "    try:\n",
        "        del pais\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    extracted_file_path = Path(f'{extracted_files}/{arquivos_pais[e]}')\n",
        "    pais = pd.DataFrame(columns=[1,2])\n",
        "    pais = pd.read_csv(filepath_or_buffer=extracted_file_path, sep=';', encoding='ISO-8859-1', skiprows=0, header=None, dtype='object')\n",
        "\n",
        "    # Tratamento do arquivo antes de inserir na base:\n",
        "    pais = pais.reset_index()\n",
        "    del pais['index']\n",
        "\n",
        "    # Renomear colunas\n",
        "    pais.columns = ['codigo', 'descricao']\n",
        "\n",
        "    # Gravar dados no banco:\n",
        "    # pais\n",
        "    pais.to_parquet(arquivos_pais[e]+'.parquet',engine='pyarrow',compression='gzip')\n",
        "    print('Arquivo ' + arquivos_pais[e] + ' inserido com sucesso no banco de dados!')\n",
        "\n",
        "try:\n",
        "    del pais\n",
        "except:\n",
        "    pass\n",
        "print('Arquivos de pais finalizados!')\n",
        "pais_insert_end = time.time()\n",
        "pais_Tempo_insert = round((pais_insert_end - pais_insert_start))\n",
        "print('Tempo de execução do processo de país (em segundos): ' + str(pais_Tempo_insert))\n",
        "\n",
        "#%%\n",
        "# Arquivos de qualificação de sócios:\n",
        "quals_insert_start = time.time()\n",
        "print(\"\"\"\n",
        "######################################\n",
        "## Arquivos de qualificação de sócios:\n",
        "######################################\n",
        "\"\"\")\n",
        "\n",
        "for e in range(0, len(arquivos_quals)):\n",
        "    print('Trabalhando no arquivo: '+arquivos_quals[e]+' [...]')\n",
        "    try:\n",
        "        del quals\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    extracted_file_path = Path(f'{extracted_files}/{arquivos_quals[e]}')\n",
        "    quals = pd.DataFrame(columns=[1,2])\n",
        "    quals = pd.read_csv(filepath_or_buffer=extracted_file_path, sep=';', encoding='ISO-8859-1', skiprows=0, header=None, dtype='object')\n",
        "\n",
        "    # Tratamento do arquivo antes de inserir na base:\n",
        "    quals = quals.reset_index()\n",
        "    del quals['index']\n",
        "\n",
        "    # Renomear colunas\n",
        "    quals.columns = ['codigo', 'descricao']\n",
        "\n",
        "    # Gravar dados no banco:\n",
        "    # quals\n",
        "    quals.to_parquet(arquivos_quals[e]+'.parquet',engine='pyarrow',compression='gzip')\n",
        "    print('Arquivo ' + arquivos_quals[e] + ' inserido com sucesso no banco de dados!')\n",
        "\n",
        "try:\n",
        "    del quals\n",
        "except:\n",
        "    pass\n",
        "print('Arquivos de quals finalizados!')\n",
        "quals_insert_end = time.time()\n",
        "quals_Tempo_insert = round((quals_insert_end - quals_insert_start))\n",
        "print('Tempo de execução do processo de qualificação de sócios (em segundos): ' + str(quals_Tempo_insert))\n",
        "\n",
        "#%%\n",
        "insert_end = time.time()\n",
        "Tempo_insert = round((insert_end - insert_start))\n",
        "\n",
        "print(\"\"\"\n",
        "#############################################\n",
        "## Processo de carga dos arquivos finalizado!\n",
        "#############################################\n",
        "\"\"\")\n",
        "\n",
        "print('Tempo total de execução do processo de carga (em segundos): ' + str(Tempo_insert)) # Tempo de execução do processo (em segundos): 17.770 (4hrs e 57 min)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}